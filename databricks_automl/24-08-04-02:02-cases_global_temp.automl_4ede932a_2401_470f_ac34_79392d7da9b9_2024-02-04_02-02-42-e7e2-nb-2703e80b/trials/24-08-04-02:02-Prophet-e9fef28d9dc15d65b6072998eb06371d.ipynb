{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a0f8818-dcdc-4a53-bf9d-5c4eb7d5c193",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Prophet training\n",
    "- This is an auto-generated notebook.\n",
    "- To reproduce these results, attach this notebook to a cluster with runtime version **13.3.x-cpu-ml-scala2.12**, and rerun it.\n",
    "- Compare trials in the [MLflow experiment](#mlflow/experiments/3275986367786501).\n",
    "- Clone this notebook into your project folder by selecting **File > Clone** in the notebook toolbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "722c6fc0-3aa3-463e-9d42-6fad6310e588",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import databricks.automl_runtime\n",
    "\n",
    "target_col = \"cases\"\n",
    "time_col = \"date\"\n",
    "unit = \"day\"\n",
    "\n",
    "horizon = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ab8a303-2289-4db2-bea7-e3bf7d7f0bea",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5164424-1b90-4ca0-81ce-ae7a6383d231",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import uuid\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "# Create temp directory to download input data from MLflow\n",
    "input_temp_dir = os.path.join(os.environ[\"SPARK_LOCAL_DIRS\"], \"tmp\", str(uuid.uuid4())[:8])\n",
    "os.makedirs(input_temp_dir)\n",
    "\n",
    "# Download the artifact and read it into a pandas DataFrame\n",
    "input_data_path = mlflow.artifacts.download_artifacts(run_id=\"b0ddf40a71a44854857c7199a5525bf1\", artifact_path=\"data\", dst_path=input_temp_dir)\n",
    "\n",
    "input_file_path = os.path.join(input_data_path, \"training_data\")\n",
    "input_file_path = \"file://\" + input_file_path\n",
    "df_loaded = ps.from_pandas(pd.read_parquet(input_file_path))\n",
    "\n",
    "# Preview data\n",
    "df_loaded.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68c16a8b-fa1e-4706-93a8-84b183f48482",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Aggregate data by `time_col`\n",
    "Group the data by `time_col`, and take average if there are multiple `target_col` values in the same group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ecf00e26-d285-46a5-b5d5-102d977f5f21",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "group_cols = [time_col]\n",
    "df_aggregated = df_loaded \\\n",
    "  .groupby(group_cols) \\\n",
    "  .agg(y=(target_col, \"avg\")) \\\n",
    "  .reset_index()\n",
    "\n",
    "df_aggregated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4281aec5-3f64-45e2-9b48-4940fb4f3d03",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Train Prophet model\n",
    "- Log relevant metrics to MLflow to track runs\n",
    "- All the runs are logged under [this MLflow experiment](#mlflow/experiments/3275986367786501)\n",
    "- Change the model parameters and re-run the training cell to log a different trial to the MLflow experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b25238e0-b993-443d-926f-48c56e5a559d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ec05ded-5ce7-4612-b460-526c9effa891",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# disable informational messages from prophet\n",
    "logging.getLogger(\"py4j\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "094ada61-706d-4a4d-a911-fc2f116344c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_columns = [\"model_json\", \"mse\", \"rmse\", \"mae\", \"mape\", \"mdape\", \"smape\", \"coverage\"]\n",
    "\n",
    "def prophet_training(history_pd):\n",
    "  from hyperopt import hp\n",
    "  from databricks.automl_runtime.forecast.prophet.forecast import ProphetHyperoptEstimator\n",
    "\n",
    "  seasonality_mode = [\"additive\", \"multiplicative\"]\n",
    "  search_space =  {\n",
    "    \"changepoint_prior_scale\": hp.loguniform(\"changepoint_prior_scale\", -6.9, -0.69),\n",
    "    \"seasonality_prior_scale\": hp.loguniform(\"seasonality_prior_scale\", -6.9, 2.3),\n",
    "    \"holidays_prior_scale\": hp.loguniform(\"holidays_prior_scale\", -6.9, 2.3),\n",
    "    \"seasonality_mode\": hp.choice(\"seasonality_mode\", seasonality_mode)\n",
    "  }\n",
    "  country_holidays=\"US\"\n",
    "  run_parallel = True\n",
    " \n",
    "  hyperopt_estim = ProphetHyperoptEstimator(horizon=horizon, frequency_unit=unit, metric=\"mdape\",interval_width=0.8,\n",
    "                   country_holidays=country_holidays, search_space=search_space, num_folds=20, max_eval=10, trial_timeout=648,\n",
    "                   random_state=64116534, is_parallel=run_parallel)\n",
    "\n",
    "  spark.conf.set(\"spark.databricks.mlflow.trackHyperopt.enabled\", \"false\")\n",
    "\n",
    "  results_pd = hyperopt_estim.fit(history_pd)\n",
    "\n",
    "  spark.conf.set(\"spark.databricks.mlflow.trackHyperopt.enabled\", \"true\")\n",
    " \n",
    "  return results_pd[result_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a6ecdb3-3ac3-413d-844b-23a44025301a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from databricks.automl_runtime.forecast.prophet.model import mlflow_prophet_log_model, ProphetModel\n",
    "\n",
    "with mlflow.start_run(experiment_id=\"3275986367786501\", run_name=\"Prophet\") as mlflow_run:\n",
    "  mlflow.set_tag(\"estimator_name\", \"Prophet\")\n",
    "  mlflow.log_param(\"holiday_country\", \"US\")\n",
    "  mlflow.log_param(\"interval_width\", 0.8)\n",
    "  df_aggregated = df_aggregated.rename(columns={time_col: \"ds\"})\n",
    "\n",
    "  forecast_results = prophet_training(df_aggregated.to_pandas())\n",
    "    \n",
    "  # Log the metrics to mlflow\n",
    "  avg_metrics = forecast_results[[\"mse\", \"rmse\", \"mae\", \"mape\", \"mdape\", \"smape\", \"coverage\"]].mean().to_frame(name=\"mean_metrics\").reset_index()\n",
    "  avg_metrics[\"index\"] = \"val_\" + avg_metrics[\"index\"].astype(str)\n",
    "  avg_metrics.set_index(\"index\", inplace=True)\n",
    "  mlflow.log_metrics(avg_metrics.to_dict()[\"mean_metrics\"])\n",
    "\n",
    "  # Create mlflow prophet model\n",
    "  model_json = forecast_results[\"model_json\"].to_list()[0]\n",
    "  prophet_model = ProphetModel(model_json, horizon, unit, time_col)\n",
    "  mlflow_prophet_log_model(prophet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae70562d-57d7-47d0-97c0-11f754882fd3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "forecast_results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b501fce-1d0e-4f2d-b775-78416faa0e4e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Analyze the predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1fc1752-dc49-4ea2-af30-572463abab95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "run_id = mlflow_run.info.run_id\n",
    "loaded_model = mlflow.pyfunc.load_model(f\"runs:/{run_id}/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5fdcb20a-847a-41b3-9053-d38e3ae95a95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "future_df = loaded_model._model_impl.python_model.make_future_dataframe()\n",
    "future_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4be8a29-e634-486f-8a74-a799c9867101",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Predict future with the default horizon\n",
    "forecast_pd = loaded_model._model_impl.python_model.model().predict(future_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5ae950c-babf-421c-a1a8-e251dc5799bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Plotly plots is turned off by default because it takes up a lot of storage.\n",
    "# Set this flag to True and re-run the notebook to see the interactive plots with plotly\n",
    "use_plotly = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd807daf-06e9-4ef8-870e-5e5eda1a63b2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get prophet model\n",
    "model = loaded_model._model_impl.python_model.model()\n",
    "predict_pd = forecast_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bdae96aa-94b2-4be9-8df6-ab5daa050408",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Plot the forecast with change points and trend\n",
    "Plot the forecast using the `plot` method with your forecast dataframe. You can use `prophet.plot.add_changepoints_to_plot` to overlay significant changepoints. An interactive figure can be created with plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eecf2c1c-a470-4f8d-96d2-b107fe7bece1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from prophet.plot import add_changepoints_to_plot, plot_plotly\n",
    "\n",
    "if use_plotly:\n",
    "    fig = plot_plotly(model, predict_pd, changepoints=True, trend=True, figsize=(1200, 600))\n",
    "else:\n",
    "    fig = model.plot(predict_pd)\n",
    "    a = add_changepoints_to_plot(fig.gca(), model, predict_pd)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3be983e-1f48-437f-ad5b-ee7b5e3aa4b1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Plot the forecast components\n",
    "Use the `Prophet.plot_components` method to see the components. By default you'll see the trend, yearly seasonality, and weekly seasonality of the time series. You can also include holidays. An interactive figure can be created with plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b79f2231-c92c-440c-8802-8569e6c91b5d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from prophet.plot import plot_components_plotly\n",
    "if use_plotly:\n",
    "    fig = plot_components_plotly(model, predict_pd, figsize=(900, 400))\n",
    "    fig.show()\n",
    "else:\n",
    "    fig = model.plot_components(predict_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e99f9648-3444-4cd6-9ecc-43328cb29481",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Show the predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d98cadc-cd54-4b89-8e43-410141003710",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predict_cols = [\"ds\", \"yhat\"]\n",
    "forecast_pd = forecast_pd.reset_index()\n",
    "display(forecast_pd[predict_cols].tail(horizon))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "24-08-04-02:02-Prophet-e9fef28d9dc15d65b6072998eb06371d",
   "widgets": {}
  },
  "name": "Prophet-e9fef28d9dc15d65b6072998eb06371d"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
