{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44d0ae69-82ec-483d-9cfb-ca4865a79979",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# ARIMA training\n",
    "- This is an auto-generated notebook.\n",
    "- To reproduce these results, attach this notebook to a cluster with runtime version **13.3.x-cpu-ml-scala2.12**, and rerun it.\n",
    "- Compare trials in the [MLflow experiment](#mlflow/experiments/3275986367786501).\n",
    "- Clone this notebook into your project folder by selecting **File > Clone** in the notebook toolbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e377dfa-f4e1-4a1f-a580-432e2ca517c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import databricks.automl_runtime\n",
    "\n",
    "target_col = \"cases\"\n",
    "time_col = \"date\"\n",
    "unit = \"day\"\n",
    "\n",
    "horizon = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f1d6baf-6e98-4fe6-8705-ce51c0c4e6e4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8d95c7c-b1b5-4f60-9d7c-42fd9f431854",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import uuid\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "# Create temp directory to download input data from MLflow\n",
    "input_temp_dir = os.path.join(os.environ[\"SPARK_LOCAL_DIRS\"], \"tmp\", str(uuid.uuid4())[:8])\n",
    "os.makedirs(input_temp_dir)\n",
    "\n",
    "# Download the artifact and read it into a pandas DataFrame\n",
    "input_data_path = mlflow.artifacts.download_artifacts(run_id=\"b0ddf40a71a44854857c7199a5525bf1\", artifact_path=\"data\", dst_path=input_temp_dir)\n",
    "\n",
    "input_file_path = os.path.join(input_data_path, \"training_data\")\n",
    "input_file_path = \"file://\" + input_file_path\n",
    "df_loaded = ps.from_pandas(pd.read_parquet(input_file_path))\n",
    "\n",
    "# Preview data\n",
    "df_loaded.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23a823e6-4d1b-4354-886b-86a54f10e306",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Aggregate data by `time_col`\n",
    "Group the data by `time_col`, and take average if there are multiple `target_col` values in the same group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac314f28-007d-404a-8186-5cd1b5da3873",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "group_cols = [time_col]\n",
    "df_aggregated = df_loaded \\\n",
    "  .groupby(group_cols) \\\n",
    "  .agg(y=(target_col, \"avg\")) \\\n",
    "  .reset_index()\n",
    "\n",
    "df_aggregated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9293329-2ece-4119-972c-a41686add652",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Train ARIMA model\n",
    "- Log relevant metrics to MLflow to track runs\n",
    "- All the runs are logged under [this MLflow experiment](#mlflow/experiments/3275986367786501)\n",
    "- Change the model parameters and re-run the training cell to log a different trial to the MLflow experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0effcfe-e04b-4630-9c1d-8ff6f588eace",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the search space of seasonal period m\n",
    "seasonal_periods = [1, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c98ada34-75a3-42a0-8189-d7346a0d1fcc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e73d89d-659d-4c30-9e0a-8e751d6b75f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_columns = [\"pickled_model\", \"mse\", \"rmse\", \"mae\", \"mape\", \"mdape\", \"smape\", \"coverage\"]\n",
    "\n",
    "def arima_training(history_pd):\n",
    "  from databricks.automl_runtime.forecast.pmdarima.training import ArimaEstimator\n",
    "\n",
    "  arima_estim = ArimaEstimator(horizon=horizon,\n",
    "                               frequency_unit=unit,\n",
    "                               metric=\"mdape\",\n",
    "                               seasonal_periods=seasonal_periods,\n",
    "                               num_folds=20)\n",
    "\n",
    "  results_pd = arima_estim.fit(history_pd)\n",
    " \n",
    "  return results_pd[result_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b69b2f6-cbb8-484a-bb16-550c8dda9a10",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from databricks.automl_runtime.forecast.pmdarima.model import ArimaModel, mlflow_arima_log_model\n",
    "\n",
    "with mlflow.start_run(experiment_id=\"3275986367786501\", run_name=\"Arima\") as mlflow_run:\n",
    "  mlflow.set_tag(\"estimator_name\", \"ARIMA\")\n",
    "\n",
    "  df_aggregated = df_aggregated.rename(columns={time_col: \"ds\"})\n",
    "\n",
    "  arima_results = arima_training(df_aggregated.to_pandas())\n",
    "    \n",
    "  # Log metrics to mlflow\n",
    "  metric_names = [\"mse\", \"rmse\", \"mae\", \"mape\", \"mdape\", \"smape\", \"coverage\"]\n",
    "  avg_metrics = arima_results[metric_names].mean().to_frame(name=\"mean_metrics\").reset_index()\n",
    "  avg_metrics[\"index\"] = \"val_\" + avg_metrics[\"index\"].astype(str)\n",
    "  avg_metrics.set_index(\"index\", inplace=True)\n",
    "  mlflow.log_metrics(avg_metrics.to_dict()[\"mean_metrics\"])\n",
    "\n",
    "  # Save the model to mlflow\n",
    "  pickled_model = arima_results[\"pickled_model\"].to_list()[0]\n",
    "  arima_model = ArimaModel(pickled_model, horizon, unit, df_aggregated[\"ds\"].min(), df_aggregated[\"ds\"].max(), time_col)\n",
    "\n",
    "  # Generate sample input dataframe\n",
    "  sample_input = df_loaded.tail(5).to_pandas()\n",
    "  sample_input[time_col] = pd.to_datetime(sample_input[time_col])\n",
    "  sample_input.drop(columns=[target_col], inplace=True)\n",
    "\n",
    "  mlflow_arima_log_model(arima_model, sample_input=sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02af9ed6-6121-4764-8516-f43226984b24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "avg_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a8e520e-898f-471e-83e3-cf2c9f1c26a0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Analyze the predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b7adce8-9996-4f50-a124-41df10c3a89e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "run_id = mlflow_run.info.run_id\n",
    "loaded_model = mlflow.pyfunc.load_model(f\"runs:/{run_id}/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93985f58-ed31-4917-80a1-d12d58ce5e2f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "future_df = loaded_model._model_impl.python_model.make_future_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ce2fb1e-1ac0-41aa-a49e-a458eb21c11a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Predict future with the default horizon\n",
    "forecast_pd = loaded_model._model_impl.python_model.predict_timeseries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96db1fa2-c20b-41ce-8e61-a344a4a6b72b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.automl_runtime.forecast.pmdarima.utils import plot\n",
    "\n",
    "history_pd = df_aggregated.to_pandas()\n",
    "# When visualizing, we ignore the first d (differencing order) points of the prediction results\n",
    "# because it is impossible for ARIMA to predict the first d values\n",
    "d = loaded_model._model_impl.python_model.model().order[1]\n",
    "fig = plot(history_pd[d:], forecast_pd[d:])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1fdc8a41-8ece-4063-8efb-d4a1f5ad9003",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Show the predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb6a21b4-1770-46b4-8d17-e5a1516e8185",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predict_cols = [\"ds\", \"yhat\"]\n",
    "forecast_pd = forecast_pd.reset_index()\n",
    "display(forecast_pd[predict_cols].tail(horizon))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "24-08-04-02:02-ARIMA-d72d2bbb2750eeeedb4004748991babd",
   "widgets": {}
  },
  "name": "ARIMA-d72d2bbb2750eeeedb4004748991babd"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
