{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "866eb8ac-fc6d-4b8b-8c0f-f0ed74fae799",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# ARIMA training\n",
    "- This is an auto-generated notebook.\n",
    "- To reproduce these results, attach this notebook to a cluster with runtime version **15.2.x-cpu-ml-scala2.12**, and rerun it.\n",
    "- Compare trials in the [MLflow experiment](#mlflow/experiments/1257688160347858).\n",
    "- Clone this notebook into your project folder by selecting **File > Clone** in the notebook toolbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5d1bc74-f855-4973-b3a2-a91b4f40d8ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import databricks.automl_runtime\n",
    "\n",
    "target_col = \"cases\"\n",
    "time_col = \"date\"\n",
    "unit = \"day\"\n",
    "\n",
    "horizon = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "151fa889-6a1e-4450-a9b4-178718690c3d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f381972c-74ae-4e86-8b4c-65e4fdd620f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import uuid\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "# Create temp directory to download input data from MLflow\n",
    "input_temp_dir = os.path.join(os.environ[\"SPARK_LOCAL_DIRS\"], \"tmp\", str(uuid.uuid4())[:8])\n",
    "os.makedirs(input_temp_dir)\n",
    "\n",
    "# Download the artifact and read it into a pandas DataFrame\n",
    "input_data_path = mlflow.artifacts.download_artifacts(run_id=\"646fc00ed14e4a6aa8db6d288d44a262\", artifact_path=\"data\", dst_path=input_temp_dir)\n",
    "\n",
    "input_file_path = os.path.join(input_data_path, \"training_data\")\n",
    "input_file_path = \"file://\" + input_file_path\n",
    "df_loaded = ps.from_pandas(pd.read_parquet(input_file_path))\n",
    "\n",
    "# Preview data\n",
    "display(df_loaded.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b53a40d-1416-4788-95a6-85a05402357f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Aggregate data by `time_col`\n",
    "Group the data by `time_col`, and take average if there are multiple `target_col` values in the same group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e53dada-52dc-4ad0-bd97-eeb4687fd61d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "group_cols = [time_col]\n",
    "df_aggregated = df_loaded \\\n",
    "  .groupby(group_cols) \\\n",
    "  .agg(y=(target_col, \"avg\")) \\\n",
    "  .reset_index()\n",
    "\n",
    "display(df_aggregated.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a6a91ae-4ed5-48f6-8288-6eded2b00d42",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Train ARIMA model\n",
    "- Log relevant metrics to MLflow to track runs\n",
    "- All the runs are logged under [this MLflow experiment](#mlflow/experiments/1257688160347858)\n",
    "- Change the model parameters and re-run the training cell to log a different trial to the MLflow experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "928551d4-23e9-4444-bc02-5b5f8c7fff76",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the search space of seasonal period m\n",
    "seasonal_periods = [1, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d29a73d9-7f3b-4ba2-b4ee-d2e1c8ecf7bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51f4c30c-b99e-4a91-b1f3-58f90eb39d8d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_columns = [\"pickled_model\", \"mse\", \"rmse\", \"mae\", \"mape\", \"mdape\", \"smape\", \"coverage\"]\n",
    "\n",
    "def arima_training(history_pd):\n",
    "  from databricks.automl_runtime.forecast.pmdarima.training import ArimaEstimator\n",
    "\n",
    "  seasonal_period_list = seasonal_periods\n",
    " \n",
    "  arima_estim = ArimaEstimator(horizon=horizon,\n",
    "                               frequency_unit=unit,\n",
    "                               metric=\"smape\",\n",
    "                               seasonal_periods=seasonal_period_list,\n",
    "                               num_folds=20)\n",
    "\n",
    "  results_pd = arima_estim.fit(history_pd)\n",
    " \n",
    "  return results_pd[result_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e9dc0b5-742e-4d37-9dd2-d89876428869",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from databricks.automl_runtime.forecast.pmdarima.model import ArimaModel, mlflow_arima_log_model\n",
    "\n",
    "with mlflow.start_run(experiment_id=\"1257688160347858\", run_name=\"Arima\") as mlflow_run:\n",
    "  mlflow.set_tag(\"estimator_name\", \"ARIMA\")\n",
    "\n",
    "  df_aggregated = df_aggregated.rename(columns={time_col: \"ds\"})\n",
    "\n",
    "  arima_results = arima_training(df_aggregated.to_pandas())\n",
    "    \n",
    "  # Log metrics to mlflow\n",
    "  metric_name_map = {\"mse\": \"mean_squared_error\", \"rmse\": \"root_mean_squared_error\", \"mae\": \"mean_absolute_error\",\n",
    "                     \"mape\": \"mean_absolute_percentage_error\", \"mdape\": \"mdape\", \"smape\": \"smape\", \"coverage\": \"coverage\"}\n",
    "  avg_metrics = arima_results[metric_name_map.keys()].rename(columns=metric_name_map).mean().to_frame(name=\"mean_metrics\").reset_index()\n",
    "  avg_metrics[\"index\"] = \"val_\" + avg_metrics[\"index\"].astype(str)\n",
    "  avg_metrics.set_index(\"index\", inplace=True)\n",
    "  mlflow.log_metrics(avg_metrics.to_dict()[\"mean_metrics\"])\n",
    "\n",
    "  # Save the model to mlflow\n",
    "  pickled_model = arima_results[\"pickled_model\"].to_list()[0]\n",
    "  arima_model = ArimaModel(pickled_model, horizon, unit, df_aggregated[\"ds\"].min(), df_aggregated[\"ds\"].max(), time_col)\n",
    "\n",
    "  # Generate sample input dataframe\n",
    "  sample_input = df_loaded.tail(5).to_pandas()\n",
    "  sample_input[time_col] = pd.to_datetime(sample_input[time_col])\n",
    "  sample_input.drop(columns=[target_col], inplace=True)\n",
    "\n",
    "  mlflow_arima_log_model(arima_model, sample_input=sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "917665e8-0932-4daf-8a4f-6e6d702b5cde",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "avg_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d7072b3-ef30-4a04-b8ca-0b10cc75c2b9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Analyze the predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a8ef18e-03b7-41a7-9173-4b39eb6f09c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "run_id = mlflow_run.info.run_id\n",
    "loaded_model = mlflow.pyfunc.load_model(f\"runs:/{run_id}/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1325affe-dfe5-4e41-b9df-c3721f7ae5dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "future_df = loaded_model._model_impl.python_model.make_future_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7223440b-8811-4767-828c-d41ec68811ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Predict future with the default horizon\n",
    "forecast_pd = loaded_model._model_impl.python_model.predict_timeseries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca6d00d3-26a5-4687-be57-140e260e1711",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.automl_runtime.forecast.pmdarima.utils import plot\n",
    "\n",
    "history_pd = df_aggregated.to_pandas()\n",
    "# When visualizing, we ignore the first d (differencing order) points of the prediction results\n",
    "# because it is impossible for ARIMA to predict the first d values\n",
    "d = loaded_model._model_impl.python_model.model().order[1]\n",
    "fig = plot(history_pd[d:], forecast_pd[d:])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "962338b7-0906-4799-9548-729f3bfb7f20",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Show the predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "605cecac-c143-4e4a-8e71-4e7ee2de02f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predict_cols = [\"ds\", \"yhat\"]\n",
    "forecast_pd = forecast_pd.reset_index()\n",
    "display(forecast_pd[predict_cols].tail(horizon))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "24-08-03-22:36-ARIMA-f8796d752562847653ac744a91497524",
   "widgets": {}
  },
  "name": "ARIMA-f8796d752562847653ac744a91497524"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
