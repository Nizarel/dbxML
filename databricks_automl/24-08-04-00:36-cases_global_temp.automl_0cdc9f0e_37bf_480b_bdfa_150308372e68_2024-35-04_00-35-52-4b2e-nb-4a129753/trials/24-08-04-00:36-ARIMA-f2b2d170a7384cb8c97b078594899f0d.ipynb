{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "830d8652-7e56-4161-bdc1-3bf5a36c7295",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# ARIMA training\n",
    "- This is an auto-generated notebook.\n",
    "- To reproduce these results, attach this notebook to a cluster with runtime version **13.3.x-cpu-ml-scala2.12**, and rerun it.\n",
    "- Compare trials in the [MLflow experiment](#mlflow/experiments/1257688160348477).\n",
    "- Clone this notebook into your project folder by selecting **File > Clone** in the notebook toolbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c6894f8-22a8-45e8-a3f0-8383a0d08e7d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import databricks.automl_runtime\n",
    "\n",
    "target_col = \"cases\"\n",
    "time_col = \"date\"\n",
    "unit = \"day\"\n",
    "\n",
    "horizon = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a08567fa-07cc-470c-b139-7b75bc4d79e8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4137cff8-9d22-4dea-a5c3-45ed91c35d6f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import uuid\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "# Create temp directory to download input data from MLflow\n",
    "input_temp_dir = os.path.join(os.environ[\"SPARK_LOCAL_DIRS\"], \"tmp\", str(uuid.uuid4())[:8])\n",
    "os.makedirs(input_temp_dir)\n",
    "\n",
    "# Download the artifact and read it into a pandas DataFrame\n",
    "input_data_path = mlflow.artifacts.download_artifacts(run_id=\"076e237584b34b63a03673556788bc87\", artifact_path=\"data\", dst_path=input_temp_dir)\n",
    "\n",
    "input_file_path = os.path.join(input_data_path, \"training_data\")\n",
    "input_file_path = \"file://\" + input_file_path\n",
    "df_loaded = ps.from_pandas(pd.read_parquet(input_file_path))\n",
    "\n",
    "# Preview data\n",
    "df_loaded.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dac56014-0771-4403-a527-92aa7a70dfd2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Aggregate data by `time_col`\n",
    "Group the data by `time_col`, and take average if there are multiple `target_col` values in the same group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1afcada0-5535-4864-888a-7b188b8603cc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "group_cols = [time_col]\n",
    "df_aggregated = df_loaded \\\n",
    "  .groupby(group_cols) \\\n",
    "  .agg(y=(target_col, \"avg\")) \\\n",
    "  .reset_index()\n",
    "\n",
    "df_aggregated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a5cc10c-4f38-44ca-9077-a970ca167924",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Train ARIMA model\n",
    "- Log relevant metrics to MLflow to track runs\n",
    "- All the runs are logged under [this MLflow experiment](#mlflow/experiments/1257688160348477)\n",
    "- Change the model parameters and re-run the training cell to log a different trial to the MLflow experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4247e6d9-14c5-40c6-93c3-0768273e1a95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the search space of seasonal period m\n",
    "seasonal_periods = [1, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e620c8d6-577a-4442-bc2a-9cde1a5cc1af",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6abcb92f-e028-4f4c-80c1-acad22b900fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_columns = [\"pickled_model\", \"mse\", \"rmse\", \"mae\", \"mape\", \"mdape\", \"smape\", \"coverage\"]\n",
    "\n",
    "def arima_training(history_pd):\n",
    "  from databricks.automl_runtime.forecast.pmdarima.training import ArimaEstimator\n",
    "\n",
    "  arima_estim = ArimaEstimator(horizon=horizon,\n",
    "                               frequency_unit=unit,\n",
    "                               metric=\"mdape\",\n",
    "                               seasonal_periods=seasonal_periods,\n",
    "                               num_folds=20)\n",
    "\n",
    "  results_pd = arima_estim.fit(history_pd)\n",
    " \n",
    "  return results_pd[result_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9664d1b-d240-4ae1-9455-ecb1cd8bce4e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from databricks.automl_runtime.forecast.pmdarima.model import ArimaModel, mlflow_arima_log_model\n",
    "\n",
    "with mlflow.start_run(experiment_id=\"1257688160348477\", run_name=\"Arima\") as mlflow_run:\n",
    "  mlflow.set_tag(\"estimator_name\", \"ARIMA\")\n",
    "\n",
    "  df_aggregated = df_aggregated.rename(columns={time_col: \"ds\"})\n",
    "\n",
    "  arima_results = arima_training(df_aggregated.to_pandas())\n",
    "    \n",
    "  # Log metrics to mlflow\n",
    "  metric_names = [\"mse\", \"rmse\", \"mae\", \"mape\", \"mdape\", \"smape\", \"coverage\"]\n",
    "  avg_metrics = arima_results[metric_names].mean().to_frame(name=\"mean_metrics\").reset_index()\n",
    "  avg_metrics[\"index\"] = \"val_\" + avg_metrics[\"index\"].astype(str)\n",
    "  avg_metrics.set_index(\"index\", inplace=True)\n",
    "  mlflow.log_metrics(avg_metrics.to_dict()[\"mean_metrics\"])\n",
    "\n",
    "  # Save the model to mlflow\n",
    "  pickled_model = arima_results[\"pickled_model\"].to_list()[0]\n",
    "  arima_model = ArimaModel(pickled_model, horizon, unit, df_aggregated[\"ds\"].min(), df_aggregated[\"ds\"].max(), time_col)\n",
    "\n",
    "  # Generate sample input dataframe\n",
    "  sample_input = df_loaded.tail(5).to_pandas()\n",
    "  sample_input[time_col] = pd.to_datetime(sample_input[time_col])\n",
    "  sample_input.drop(columns=[target_col], inplace=True)\n",
    "\n",
    "  mlflow_arima_log_model(arima_model, sample_input=sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81529f86-90e2-49f6-994b-25b93a50f6f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "avg_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56d9c9d0-128a-4c37-9d8e-f21402e8190e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Analyze the predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a51fc08a-25e0-47c2-82ee-9a67b488a357",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "run_id = mlflow_run.info.run_id\n",
    "loaded_model = mlflow.pyfunc.load_model(f\"runs:/{run_id}/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf0f72e4-16ad-49e4-ac1e-0d6550b5b4fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "future_df = loaded_model._model_impl.python_model.make_future_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14425d85-e98a-4a7b-bdd4-e2e4dbf196d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Predict future with the default horizon\n",
    "forecast_pd = loaded_model._model_impl.python_model.predict_timeseries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "065e2277-5db1-4abe-b291-acf4aef8ddae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.automl_runtime.forecast.pmdarima.utils import plot\n",
    "\n",
    "history_pd = df_aggregated.to_pandas()\n",
    "# When visualizing, we ignore the first d (differencing order) points of the prediction results\n",
    "# because it is impossible for ARIMA to predict the first d values\n",
    "d = loaded_model._model_impl.python_model.model().order[1]\n",
    "fig = plot(history_pd[d:], forecast_pd[d:])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ebf9098-3349-4372-b5a6-b1fc3dfcd06a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Show the predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d1321ea-1947-4d8b-8fb8-aadf629290a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predict_cols = [\"ds\", \"yhat\"]\n",
    "forecast_pd = forecast_pd.reset_index()\n",
    "display(forecast_pd[predict_cols].tail(horizon))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "24-08-04-00:36-ARIMA-f2b2d170a7384cb8c97b078594899f0d",
   "widgets": {}
  },
  "name": "ARIMA-f2b2d170a7384cb8c97b078594899f0d"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
